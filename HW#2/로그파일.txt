=== epoch:1, train acc:0.297, test acc:0.304 ===
train loss:2.299340195199625
train loss:0.7769801161988612
train loss:0.6490245326116514
train loss:0.5516208745245575
train loss:0.5808442966223214
train loss:0.5401200563414588
train loss:0.45947914817292357
train loss:0.49064324281505306
train loss:0.3443652116244328
train loss:0.4858347185771489
=== epoch:2, train acc:0.839, test acc:0.831 ===
train loss:0.4327722538690077
train loss:0.3950424853749322
train loss:0.34727147311987094
train loss:0.5087062280515714
train loss:0.3338741714545914
train loss:0.32702742472381024
train loss:0.392601536400386
train loss:0.3552432898320222
train loss:0.39307046900365245
train loss:0.4392537587369514
=== epoch:3, train acc:0.882, test acc:0.866 ===
train loss:0.32886804164336103
train loss:0.1826912526990833
train loss:0.3074099705579632
train loss:0.2823304506747953
train loss:0.2809914494871587
train loss:0.2733115310529879
train loss:0.2621302807909968
train loss:0.2776536340134215
train loss:0.2810965271608527
train loss:0.31545758302387605
=== epoch:4, train acc:0.905, test acc:0.89 ===
train loss:0.311817442423388
train loss:0.26933314454178087
train loss:0.35362445067090703
train loss:0.3349208712262052
train loss:0.31561600355823877
train loss:0.3485543426326836
train loss:0.42893061610292726
train loss:0.26317347069858393
train loss:0.26648594013404614
train loss:0.18477497523560119
=== epoch:5, train acc:0.908, test acc:0.882 ===
train loss:0.37428105802577294
train loss:0.17261152470339652
train loss:0.291836992790677
train loss:0.21747448480511025
train loss:0.24954866886460908
train loss:0.29129603288252814
train loss:0.21846450173392895
train loss:0.27511715105338347
train loss:0.26121808637671845
train loss:0.39677254035663945
=== epoch:6, train acc:0.923, test acc:0.901 ===
train loss:0.22852294368711618
train loss:0.21793818149722877
train loss:0.15381633214912674
train loss:0.1975826467020984
train loss:0.15211911878716247
train loss:0.23471855423349905
train loss:0.2028573529781573
train loss:0.2796382445886164
train loss:0.2386337486409087
train loss:0.20056611744364944
=== epoch:7, train acc:0.933, test acc:0.902 ===
train loss:0.2696894482349472
train loss:0.2713754232748676
train loss:0.21433244519509784
train loss:0.19181323724683885
train loss:0.1265075443574898
train loss:0.156969431182792
train loss:0.16857056003801849
train loss:0.24552946004347828
train loss:0.18432132808907642
train loss:0.2540101102447096
=== epoch:8, train acc:0.938, test acc:0.9 ===
train loss:0.3088760678140835
train loss:0.15286390224438004
train loss:0.23669027985455787
train loss:0.13158179757742358
train loss:0.28473248003945
train loss:0.22529575356412582
train loss:0.18234466311580033
train loss:0.2770112666586091
train loss:0.14733283766992825
train loss:0.1898793579102495
=== epoch:9, train acc:0.929, test acc:0.901 ===
train loss:0.22619005086249394
train loss:0.14558454115275604
train loss:0.21426466859133586
train loss:0.24060452162024923
train loss:0.21144203103217085
train loss:0.22974279708595774
train loss:0.3090746377181652
train loss:0.1736835062887236
train loss:0.16023765268321646
train loss:0.15934201503692427
=== epoch:10, train acc:0.936, test acc:0.901 ===
train loss:0.13722619399585925
train loss:0.2614067527961677
train loss:0.17754152720519253
train loss:0.08600312427744493
train loss:0.14364541523795837
train loss:0.16165003458668953
train loss:0.17265610544308216
train loss:0.2651998289249838
train loss:0.12224840660634256
train loss:0.1991327620522166
=== epoch:11, train acc:0.949, test acc:0.904 ===
train loss:0.2116939761687554
train loss:0.12604041725480522
train loss:0.13018611844138425
train loss:0.16635323354526954
train loss:0.21644146081196072
train loss:0.1296751372681518
train loss:0.2850625206739301
train loss:0.21969636147084898
train loss:0.06643082598276626
train loss:0.13550015154780604
=== epoch:12, train acc:0.954, test acc:0.909 ===
train loss:0.1738858432728857
train loss:0.10702026345514776
train loss:0.18611876697298235
train loss:0.140204917376692
train loss:0.12487177569858064
train loss:0.07143521256383976
train loss:0.11451367282200939
train loss:0.12130745552227079
train loss:0.18432073567659363
train loss:0.1641598827456854
=== epoch:13, train acc:0.962, test acc:0.906 ===
train loss:0.1496349957356706
train loss:0.12625390129981515
train loss:0.11923911241331105
train loss:0.13643168329623423
train loss:0.08246795734430135
train loss:0.11438955613297336
train loss:0.14170232685799447
train loss:0.07499327822633736
train loss:0.20498279126816565
train loss:0.07265941476697063
=== epoch:14, train acc:0.967, test acc:0.915 ===
train loss:0.11747663341155525
train loss:0.17559632304056896
train loss:0.06690846474964689
train loss:0.07313496879539842
train loss:0.12291368811053449
train loss:0.04201206241121106
train loss:0.12112966942175561
train loss:0.08583723933235785
train loss:0.09601075020643496
train loss:0.038244945830579885
=== epoch:15, train acc:0.964, test acc:0.91 ===
train loss:0.07562363552243129
train loss:0.08101212459907449
train loss:0.1229074102093259
train loss:0.03585485426643223
train loss:0.08765424540809923
train loss:0.11093188124596585
train loss:0.10160419052152513
train loss:0.1214912517974068
train loss:0.08411125885672222
train loss:0.09232394215393848
=== epoch:16, train acc:0.966, test acc:0.905 ===
train loss:0.03406655377949904
train loss:0.08559527864911631
train loss:0.061296032614170694
train loss:0.10693797996210119
train loss:0.14033029199662
train loss:0.06804177200028456
train loss:0.127543538645688
train loss:0.047932963742367024
train loss:0.08712664855752923
train loss:0.052433139925490674
=== epoch:17, train acc:0.972, test acc:0.905 ===
train loss:0.07209216146790645
train loss:0.13460458722176216
train loss:0.11381820098383473
train loss:0.04289506606940892
train loss:0.11184153903411798
train loss:0.06221673066873521
train loss:0.07985218036135996
train loss:0.0939866343901405
train loss:0.04712377915287354
train loss:0.05430696736236046
=== epoch:18, train acc:0.965, test acc:0.904 ===
train loss:0.160218996484834
train loss:0.22766063796457942
train loss:0.10783470726561997
train loss:0.040328448696044523
train loss:0.0772934631831376
train loss:0.07145711535882851
train loss:0.13958200834772888
train loss:0.04515256083611506
train loss:0.0908338715659646
train loss:0.0803136196320414
=== epoch:19, train acc:0.971, test acc:0.895 ===
train loss:0.09288366343672111
train loss:0.08006281145365012
train loss:0.09199783684934947
train loss:0.059547788493737486
train loss:0.04223812657917528
train loss:0.06891634353744178
train loss:0.04685514113671443
train loss:0.11228345721831316
train loss:0.0485540058115116
train loss:0.07515261315603339
=== epoch:20, train acc:0.975, test acc:0.908 ===
train loss:0.05390298848679437
train loss:0.06482912098498603
train loss:0.07131531381725088
train loss:0.07727583969151242
train loss:0.08223264690947638
train loss:0.052106694309444465
train loss:0.05633857646357301
train loss:0.03887744148373317
train loss:0.04796846567179473
train loss:0.06176635375205688
=============== Final Test Accuracy ===============
train acc:0.9758833333333333, test acc:0.9141
